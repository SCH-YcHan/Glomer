{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0daac67-2dca-494d-8f33-bdadab211bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from mmseg.apis import init_model, inference_model, show_result_pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2320cbd-768a-4e19-b7ec-1832e3e3c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../../work_dirs/pidnet-s_2xb6-120k_1024x1024-glomer/pidnet-s_2xb6-120k_1024x1024-glomer.py'\n",
    "checkpoint_path = '../../work_dirs/pidnet-s_2xb6-120k_1024x1024-glomer/iter_120000.pth'\n",
    "img_path = '../../test_img/test_x20.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aa3abdc-4a5d-427e-b450-ebb3e5c260d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\decode_heads\\decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\losses\\cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../../work_dirs/pidnet-s_2xb6-120k_1024x1024-glomer/iter_120000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\utils\\wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (256, 84) is `x+1` and out size (2048, 672) is `nx+1`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.00 GiB (GPU 0; 11.00 GiB total capacity; 133.37 MiB already allocated; 5.26 GiB free; 3.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m init_model(config_path, checkpoint_path, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# inference on given image\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43minference_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# save the visualization result, the output image would be found at the path `work_dirs/result.png`\u001b[39;00m\n\u001b[0;32m      8\u001b[0m vis_iamge \u001b[38;5;241m=\u001b[39m show_result_pyplot(model, img_path, result, out_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../pred_result/test_x20_origin.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\apis\\inference.py:147\u001b[0m, in \u001b[0;36minference_model\u001b[1;34m(model, img)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 147\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m is_batch \u001b[38;5;28;01melse\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HuBMAP\\lib\\site-packages\\mmengine\\model\\base_model\\base_model.py:145\u001b[0m, in \u001b[0;36mBaseModel.test_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"``BaseModel`` implements ``test_step`` the same as ``val_step``.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    list: The predictions of given data.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preprocessor(data, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HuBMAP\\lib\\site-packages\\mmengine\\model\\base_model\\base_model.py:340\u001b[0m, in \u001b[0;36mBaseModel._run_forward\u001b[1;34m(self, data, mode)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Unpacks data for :meth:`forward`\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m    dict or list: Results of training or testing mode.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 340\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    342\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HuBMAP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\segmentors\\base.py:96\u001b[0m, in \u001b[0;36mBaseSegmentor.forward\u001b[1;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(inputs, data_samples)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(inputs, data_samples)\n",
      "File \u001b[1;32mc:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\segmentors\\encoder_decoder.py:222\u001b[0m, in \u001b[0;36mEncoderDecoder.predict\u001b[1;34m(self, inputs, data_samples)\u001b[0m\n\u001b[0;32m    212\u001b[0m     batch_img_metas \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    214\u001b[0m             ori_shape\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m             padding_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    218\u001b[0m     ] \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    220\u001b[0m seg_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(inputs, batch_img_metas)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\segmentors\\base.py:178\u001b[0m, in \u001b[0;36mBaseSegmentor.postprocess_result\u001b[1;34m(self, seg_logits, data_samples)\u001b[0m\n\u001b[0;32m    175\u001b[0m             i_seg_logits \u001b[38;5;241m=\u001b[39m i_seg_logits\u001b[38;5;241m.\u001b[39mflip(dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, ))\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# resize as original shape\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     i_seg_logits \u001b[38;5;241m=\u001b[39m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi_seg_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mori_shape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     i_seg_logits \u001b[38;5;241m=\u001b[39m seg_logits[i]\n",
      "File \u001b[1;32mc:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\utils\\wrappers.py:27\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(input, size, scale_factor, mode, align_corners, warning)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m ((output_h \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m output_w \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m input_h \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     20\u001b[0m                  \u001b[38;5;129;01mand\u001b[39;00m input_w \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (output_h \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (input_h \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m (output_w \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (input_w \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m     22\u001b[0m                 warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     23\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen align_corners=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malign_corners\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe output would more aligned if \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     25\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(input_h,\u001b[38;5;250m \u001b[39minput_w)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is `x+1` and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     26\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(output_h,\u001b[38;5;250m \u001b[39moutput_w)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is `nx+1`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HuBMAP\\lib\\site-packages\\torch\\nn\\functional.py:3959\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   3957\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m antialias:\n\u001b[0;32m   3958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_upsample_bilinear2d_aa(\u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[1;32m-> 3959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_bilinear2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3961\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.00 GiB (GPU 0; 11.00 GiB total capacity; 133.37 MiB already allocated; 5.26 GiB free; 3.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_model(config_path, checkpoint_path, device='cuda:0')\n",
    "\n",
    "# inference on given image\n",
    "result = inference_model(model, img_path)\n",
    "\n",
    "# save the visualization result, the output image would be found at the path `work_dirs/result.png`\n",
    "vis_iamge = show_result_pyplot(model, img_path, result, out_file='../pred_result/test_x20.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0feb7ad-d479-48f9-be02-a6a2f6a467c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
