{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730a6fd8-78b2-4c05-9e7a-8ea9bb541f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x2a06d8 \n",
      "0x2400ba \n",
      "0x50248 \n",
      "0x100e4 \n",
      "0xa0ec2 Real-time segmentation - Chrome\n",
      "0x30e06 Motic Digital Slide Assistant\n",
      "0xa0882 1e2425f28_0044.png ‎- 사진\n",
      "0x120a1e *window_faster_256.py - Windows 메모장\n",
      "0x340b92 작업 관리자\n",
      "0xf0d54 Anaconda Prompt (anaconda3) - jupyter  notebook\n",
      "0x610550 code\n",
      "0x10216 스티커 메모\n",
      "0x350a7c Microsoft.Photos.exe 속성\n",
      "0x610552 \n",
      "0x5026e Anaconda Prompt (anaconda3) - python  mmsegmentation/tools/train.py mmsegmentation/configs/pidnet/pidnet-l_2xb6-120k_1024x1024-star3.py\n",
      "0x90b4e \n",
      "0x2019c \n",
      "0x301dc 스티커 메모\n",
      "0x380838 \n",
      "0x101aa \n",
      "0x10188 \n",
      "0x10186 \n",
      "0x104a8 Microsoft Text Input Application\n",
      "0x2d0872 uncategorized Workspace – Weights & Biases - Chrome\n",
      "0x706d0 \n",
      "0x801c6 \n",
      "0x10158 Program Manager\n"
     ]
    }
   ],
   "source": [
    "import win32gui\n",
    "\n",
    "def list_window_names():\n",
    "    def winEnumHandler(hwnd, ctx):\n",
    "        if win32gui.IsWindowVisible(hwnd):\n",
    "            print(hex(hwnd), win32gui.GetWindowText(hwnd))\n",
    "    win32gui.EnumWindows(winEnumHandler, None)\n",
    "\n",
    "list_window_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e8bd6c-06db-45bd-bdd5-29731f5716b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\decode_heads\\decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\losses\\cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../../work_dirs/pidnet-s_2xb6-120k_256x256-glomer/iter_300000.pth\n"
     ]
    }
   ],
   "source": [
    "import win32gui, win32ui, win32con\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from time import time\n",
    "from mmseg.apis import init_model, inference_model, show_result_pyplot\n",
    "\n",
    "config_path = '../../work_dirs/pidnet-s_2xb6-120k_256x256-glomer/pidnet-s_2xb6-120k_256x256-glomer.py'\n",
    "checkpoint_path = '../../work_dirs/pidnet-s_2xb6-120k_256x256-glomer/iter_300000.pth'\n",
    "\n",
    "model = init_model(config_path, checkpoint_path, device='cuda:0')\n",
    "\n",
    "class WindowCapture:\n",
    "\n",
    "    # properties\n",
    "    w = 0\n",
    "    h = 0\n",
    "    hwnd = None\n",
    "    cropped_x = 0\n",
    "    cropped_y = 0\n",
    "    offset_x = 0\n",
    "    offset_y = 0\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, window_name):\n",
    "        # find the handle for the window we want to capture\n",
    "        self.hwnd = win32gui.FindWindow(None, window_name)\n",
    "        if not self.hwnd:\n",
    "            raise Exception('Window not found: {}'.format(window_name))\n",
    "\n",
    "        # get the window size\n",
    "        window_rect = win32gui.GetWindowRect(self.hwnd)\n",
    "        self.w = window_rect[2] - window_rect[0]\n",
    "        self.h = window_rect[3] - window_rect[1]\n",
    "\n",
    "        # account for the window border and titlebar and cut them off\n",
    "        border_pixels = 8\n",
    "        titlebar_pixels = 30\n",
    "        self.w = self.w - (border_pixels * 2)\n",
    "        self.h = self.h - titlebar_pixels - border_pixels\n",
    "        self.cropped_x = border_pixels\n",
    "        self.cropped_y = titlebar_pixels\n",
    "\n",
    "        # set the cropped coordinates offset so we can translate screenshot\n",
    "        # images into actual screen positions\n",
    "        self.offset_x = window_rect[0] + self.cropped_x\n",
    "        self.offset_y = window_rect[1] + self.cropped_y\n",
    "\n",
    "    def get_screenshot(self):\n",
    "\n",
    "        # get the window image data\n",
    "        wDC = win32gui.GetWindowDC(self.hwnd)\n",
    "        dcObj = win32ui.CreateDCFromHandle(wDC)\n",
    "        cDC = dcObj.CreateCompatibleDC()\n",
    "        dataBitMap = win32ui.CreateBitmap()\n",
    "        dataBitMap.CreateCompatibleBitmap(dcObj, self.w, self.h)\n",
    "        cDC.SelectObject(dataBitMap)\n",
    "        cDC.BitBlt((0, 0), (self.w, self.h), dcObj, (self.cropped_x, self.cropped_y), win32con.SRCCOPY)\n",
    "\n",
    "        # convert the raw data into a format opencv can read\n",
    "        #dataBitMap.SaveBitmapFile(cDC, 'debug.bmp')\n",
    "        signedIntsArray = dataBitMap.GetBitmapBits(True)\n",
    "        img = np.fromstring(signedIntsArray, dtype='uint8')\n",
    "        img.shape = (self.h, self.w, 4)\n",
    "\n",
    "        # free resources\n",
    "        dcObj.DeleteDC()\n",
    "        cDC.DeleteDC()\n",
    "        win32gui.ReleaseDC(self.hwnd, wDC)\n",
    "        win32gui.DeleteObject(dataBitMap.GetHandle())\n",
    "\n",
    "        # drop the alpha channel, or cv.matchTemplate() will throw an error like:\n",
    "        #   error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() \n",
    "        #   && _img.dims() <= 2 in function 'cv::matchTemplate'\n",
    "        img = img[...,:3]\n",
    "\n",
    "        # make image C_CONTIGUOUS to avoid errors that look like:\n",
    "        #   File ... in draw_rectangles\n",
    "        #   TypeError: an integer is required (got type tuple)\n",
    "        # see the discussion here:\n",
    "        # https://github.com/opencv/opencv/issues/14866#issuecomment-580207109\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b4f21d-1853-4318-a052-dec2673a760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_38128\\3389412457.py:66: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  img = np.fromstring(signedIntsArray, dtype='uint8')\n",
      "c:\\users\\user\\desktop\\hubmap\\mmsegmentation\\mmseg\\models\\utils\\wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (32, 41) is `x+1` and out size (256, 322) is `nx+1`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "wincap = WindowCapture(\"Motic Digital Slide Assistant\")\n",
    "\n",
    "screenshot = wincap.get_screenshot()\n",
    "pred_screenshot = inference_model(model, screenshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcab4d6-3678-4d55-8261-9d4651ba70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map = pred_screenshot.pred_sem_seg.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c7382d-8a9c-4487-b1f4-c8a28a88bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map = seg_map.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ddffde-0054-4b3d-97cd-c705620719cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_colored = np.zeros((seg_map.shape[0], seg_map.shape[1], 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca5ca271-7c2e-4ada-99f8-90c23f40470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color in enumerate(model.dataset_meta[\"palette\"]):\n",
    "    seg_colored[seg_map == i] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8564515d-3099-4c10-962c-2c012394c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_screenshot = cv.addWeighted(screenshot, 0.7, seg_colored, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7ecd1-135e-4e01-95f8-2ca1ae108e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
