{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0965accc-e318-4ba3-a2b9-aecdbcc732cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a35b4d0-7418-4842-adf9-a6f323b70997",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"configs\"):\n",
    "    os.mkdir(\"configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2761d-2cc5-4e19-abc1-da459c54a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model\n",
    "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth'\n",
    "crop_size = (1024, 1024)\n",
    "data_preprocessor = dict(\n",
    "    type='SegDataPreProcessor',\n",
    "    mean=[123.675, 116.28, 103.53],\n",
    "    std=[58.395, 57.12, 57.375],\n",
    "    bgr_to_rgb=True,\n",
    "    pad_val=0,\n",
    "    seg_pad_val=255,\n",
    "    size=crop_size\n",
    ")\n",
    "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "model = dict(\n",
    "    type='EncoderDecoder',\n",
    "    data_preprocessor=data_preprocessor,\n",
    "    backbone=dict(\n",
    "        type='PIDNet',\n",
    "        in_channels=3,\n",
    "        channels=32,\n",
    "        ppm_channels=96,\n",
    "        num_stem_blocks=2,\n",
    "        num_branch_blocks=3,\n",
    "        align_corners=False,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='ReLU', inplace=True),\n",
    "        init_cfg=dict(type='Pretrained', checkpoint=checkpoint_file)),\n",
    "    decode_head=dict(\n",
    "        type='PIDHead',\n",
    "        in_channels=128,\n",
    "        channels=128,\n",
    "        num_classes=2,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='ReLU', inplace=True),\n",
    "        align_corners=True,\n",
    "        loss_decode=[\n",
    "            dict(\n",
    "                type='CrossEntropyLoss',\n",
    "                use_sigmoid=False,\n",
    "                loss_weight=0.4\n",
    "            ),\n",
    "            dict(\n",
    "                type='OhemCrossEntropy',\n",
    "                thres=0.9,\n",
    "                min_kept=131072,\n",
    "                loss_weight=1.0\n",
    "            ),\n",
    "            dict(type='BoundaryLoss', loss_weight=20.0),\n",
    "            dict(\n",
    "                type='OhemCrossEntropy',\n",
    "                thres=0.9,\n",
    "                min_kept=131072,\n",
    "                loss_weight=1.0\n",
    "            )\n",
    "        ]),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode='whole')\n",
    ")\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'CustomDataset'  # Dataset type, this will be used to define the dataset\n",
    "data_root = 'C:/Users/user/Desktop/HuBMAP/cut_1024/'  # Root path of data\n",
    "backend_args = None # Arguments to instantiate the corresponding file backend\n",
    "classes = ('background', 'glomerulus')\n",
    "crop_size = (1024, 1024)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=(2048, 1024),\n",
    "        ratio_range=(0.5, 2.0),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]\n",
    "tta_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(\n",
    "        type='TestTimeAug',\n",
    "        transforms=[\n",
    "            [\n",
    "                dict(type='Resize', scale_factor=r, keep_ratio=True)\n",
    "                for r in img_ratios\n",
    "            ],\n",
    "            [\n",
    "                dict(type='RandomFlip', prob=0., direction='horizontal'),\n",
    "                dict(type='RandomFlip', prob=1., direction='horizontal')\n",
    "            ], [dict(type='LoadAnnotations')], [dict(type='PackSegInputs')]\n",
    "        ])\n",
    "]\n",
    "train_dataloader = dict(\n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        data_prefix=dict(\n",
    "            img_path='train_img/',\n",
    "            seg_map_path='train_mask/'\n",
    "        ),\n",
    "        pipeline=train_pipeline)\n",
    ")\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        data_prefix=dict(\n",
    "            img_path='val_img/',\n",
    "            seg_map_path='val_mask/'\n",
    "        ),\n",
    "        pipeline=test_pipeline)\n",
    ")\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])\n",
    "test_evaluator = val_evaluator\n",
    "\n",
    "# optimizer\n",
    "iters = 120000\n",
    "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer, clip_grad=None)\n",
    "\n",
    "# learning policy\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='PolyLR',\n",
    "        eta_min=0,\n",
    "        power=0.9,\n",
    "        begin=0,\n",
    "        end=iters,\n",
    "        by_epoch=False)\n",
    "]\n",
    "\n",
    "# setting hook\n",
    "default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook', \n",
    "        interval=iters // 10, \n",
    "        by_epoch=False\n",
    "    ),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='SegVisualizationHook')\n",
    ")\n",
    "\n",
    "randomness = dict(seed=3500)\n",
    "\n",
    "# setting scope\n",
    "default_scope = 'mmseg'\n",
    "\n",
    "# setting env config\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=False,\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
    "    dist_cfg=dict(backend='nccl'),\n",
    ")\n",
    "\n",
    "# setting visualizer\n",
    "vis_backends = [dict(type='LocalVisBackend')]  \n",
    "visualizer = dict(\n",
    "    type=\"Visualizer\", \n",
    "    vis_backends=[dict(type=\"WandbVisBackend\")]\n",
    ")\n",
    "\n",
    "# settiing logger\n",
    "log_config = dict(\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        dict(\n",
    "            type='WandbLoggerHook',\n",
    "            init_kwargs={'project': 'mmsegmentation'},\n",
    "            interval=10,\n",
    "            log_dir='./work_dirs/PIDNet_log'\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_processor = dict(\n",
    "    type='LogProcessor',\n",
    "    window_size=50,\n",
    "    by_epoch=True\n",
    ")\n",
    "log_level = 'INFO'\n",
    "load_from = None\n",
    "resume = False\n",
    "\n",
    "tta_model = dict(type='SegTTAModel')\n",
    "\n",
    "# setting trian test cfg\n",
    "train_cfg = dict(\n",
    "    type='IterBasedTrainLoop', \n",
    "    max_iters=iters, \n",
    "    val_interval=iters // 10\n",
    ")\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68b3b7-e5a2-4967-bcf7-cb61bc2c4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모장에 위 내용 복사 후 config 파일 내부에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7325f0-0160-4217-bf3e-d9b1be70e5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0fba6-fccf-4fb5-8131-8bca4029a048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde1897-933f-46de-abdd-8e3c4b80cdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
