{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff8128a-99be-431f-b3f5-ed530ee99b9b",
   "metadata": {},
   "source": [
    "# .py로 만들어서 올바른 경로에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8466a8-71dd-469c-a49f-d95e93138297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path: mmsegmentation/mmseg/datasets/glomer.py\n",
    "from mmseg.registry import DATASETS\n",
    "from .basesegdataset import BaseSegDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class GlomerDataset(BaseSegDataset):\n",
    "\n",
    "    METAINFO = dict(\n",
    "        classes=('background', 'glomerulus'),\n",
    "        palette=[[0, 0, 0], [255, 0, 0]]\n",
    "    )\n",
    "\n",
    "    def __init__(self,\n",
    "                 img_suffix='.png',\n",
    "                 seg_map_suffix='.png',\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            img_suffix=img_suffix, \n",
    "            seg_map_suffix=seg_map_suffix, \n",
    "            **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ac8db-5e31-48e5-aeef-279b8957a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path: mmsegmentation/configs/_base_/datasets/glomer_1024x1024.py\n",
    "# dataset settings\n",
    "dataset_type = 'GlomerDataset'\n",
    "data_root = 'C:/Users/user/Desktop/HuBMAP/cut_1024/'\n",
    "crop_size = (1024, 1024)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=(2048, 1024),\n",
    "        ratio_range=(0.5, 2.0),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='GenerateEdge', edge_width=4),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]\n",
    "tta_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(\n",
    "        type='TestTimeAug',\n",
    "        transforms=[\n",
    "            [\n",
    "                dict(type='Resize', scale_factor=r, keep_ratio=True)\n",
    "                for r in img_ratios\n",
    "            ],\n",
    "            [\n",
    "                dict(type='RandomFlip', prob=0., direction='horizontal'),\n",
    "                dict(type='RandomFlip', prob=1., direction='horizontal')\n",
    "            ], [dict(type='LoadAnnotations')], [dict(type='PackSegInputs')]\n",
    "        ])\n",
    "]\n",
    "train_dataloader = dict(\n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        data_prefix=dict(\n",
    "            img_path='train_img/',\n",
    "            seg_map_path='train_mask/'\n",
    "        ),\n",
    "        pipeline=train_pipeline)\n",
    ")\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        data_prefix=dict(\n",
    "            img_path='val_img/',\n",
    "            seg_map_path='val_mask/'\n",
    "        ),\n",
    "        pipeline=test_pipeline)\n",
    ")\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])\n",
    "test_evaluator = val_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7325f0-0160-4217-bf3e-d9b1be70e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path: mmsegmentation/configs/pidnet/pidnet-s_2xb6-120k_1024x1024-glomer.py\n",
    "_base_ = [\n",
    "    '../_base_/datasets/glomer_1024x1024.py',\n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth'\n",
    "crop_size = (1024, 1024)\n",
    "data_preprocessor = dict(\n",
    "    type='SegDataPreProcessor',\n",
    "    mean=[123.675, 116.28, 103.53],\n",
    "    std=[58.395, 57.12, 57.375],\n",
    "    bgr_to_rgb=True,\n",
    "    pad_val=0,\n",
    "    seg_pad_val=255,\n",
    "    size=crop_size\n",
    ")\n",
    "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "model = dict(\n",
    "    type='EncoderDecoder',\n",
    "    data_preprocessor=data_preprocessor,\n",
    "    backbone=dict(\n",
    "        type='PIDNet',\n",
    "        in_channels=3,\n",
    "        channels=32,\n",
    "        ppm_channels=96,\n",
    "        num_stem_blocks=2,\n",
    "        num_branch_blocks=3,\n",
    "        align_corners=False,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='ReLU', inplace=True),\n",
    "        init_cfg=dict(type='Pretrained', checkpoint=checkpoint_file)),\n",
    "    decode_head=dict(\n",
    "        type='PIDHead',\n",
    "        in_channels=128,\n",
    "        channels=128,\n",
    "        num_classes=2,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='ReLU', inplace=True),\n",
    "        align_corners=True,\n",
    "        loss_decode=[\n",
    "            dict(\n",
    "                type='CrossEntropyLoss',\n",
    "                use_sigmoid=False,\n",
    "                loss_weight=0.4\n",
    "            ),\n",
    "            dict(\n",
    "                type='OhemCrossEntropy',\n",
    "                thres=0.9,\n",
    "                min_kept=131072,\n",
    "                loss_weight=1.0\n",
    "            ),\n",
    "            dict(type='BoundaryLoss', loss_weight=20.0),\n",
    "            dict(\n",
    "                type='OhemCrossEntropy',\n",
    "                thres=0.9,\n",
    "                min_kept=131072,\n",
    "                loss_weight=1.0\n",
    "            )\n",
    "        ]),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode='whole')\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "iters = 120000\n",
    "optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer, clip_grad=None)\n",
    "\n",
    "# learning policy\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='PolyLR',\n",
    "        eta_min=0,\n",
    "        power=0.9,\n",
    "        begin=0,\n",
    "        end=iters,\n",
    "        by_epoch=False)\n",
    "]\n",
    "\n",
    "# setting visualizer\n",
    "visualizer = dict(\n",
    "    type=\"Visualizer\", \n",
    "    vis_backends=[dict(type='LocalVisBackend'),\n",
    "                      dict(type=\"WandbVisBackend\")]\n",
    ")\n",
    "\n",
    "# settiing logger\n",
    "log_config = dict(\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        dict(\n",
    "            type='WandbLoggerHook',\n",
    "            init_kwargs={'project': 'mmsegmentation'},\n",
    "            interval=10,\n",
    "            log_dir='./work_dirs/PIDNet_log'\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_processor = dict(\n",
    "    type='LogProcessor',\n",
    "    window_size=50,\n",
    "    by_epoch=True\n",
    ")\n",
    "\n",
    "# setting trian test cfg\n",
    "train_cfg = dict(\n",
    "    type='IterBasedTrainLoop', \n",
    "    max_iters=iters, \n",
    "    val_interval=iters // 10\n",
    ")\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "\n",
    "# setting hook\n",
    "default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook', \n",
    "        interval=iters // 10, \n",
    "        by_epoch=False\n",
    "    ),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='SegVisualizationHook', draw=True, interval=1)\n",
    ")\n",
    "\n",
    "randomness = dict(seed=3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab3488-934e-4735-9cd3-a57995d56d9f",
   "metadata": {},
   "source": [
    "# 파일 내용 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde1897-933f-46de-abdd-8e3c4b80cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmsegmentation/mmseg/utils/class_names.py\n",
    "def glomer_classes():\n",
    "    return ['background', 'glomerulus']\n",
    "\n",
    "def glomer_palette():\n",
    "    return [[0, 0, 0], [255, 0, 0]]\n",
    "\n",
    "dataset_aliases = {\n",
    "    'glomer': ['glomer'], #추가되는 부분\n",
    "    'cityscapes': ['cityscapes'],\n",
    "    'ade': ['ade', 'ade20k'],\n",
    "    'voc': ['voc', 'pascal_voc', 'voc12', 'voc12aug'],\n",
    "    'loveda': ['loveda'],\n",
    "    'potsdam': ['potsdam'],\n",
    "    'vaihingen': ['vaihingen'],\n",
    "    'cocostuff': [\n",
    "        'cocostuff', 'cocostuff10k', 'cocostuff164k', 'coco-stuff',\n",
    "        'coco-stuff10k', 'coco-stuff164k', 'coco_stuff', 'coco_stuff10k',\n",
    "        'coco_stuff164k'\n",
    "    ],\n",
    "    'isaid': ['isaid', 'iSAID'],\n",
    "    'stare': ['stare', 'STARE'],\n",
    "    'lip': ['LIP', 'lip'],\n",
    "    'mapillary_v1': ['mapillary_v1'],\n",
    "    'mapillary_v2': ['mapillary_v2'],\n",
    "    'bdd100k': ['bdd100k']\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
